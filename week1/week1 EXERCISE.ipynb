{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please answer this technical question:\n",
    "What is the simcard specification of iphone pro 17?}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1868459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '\\nPlease answer this technical question:\\nWhat is the simcard specification of iphone pro 17?}\\n'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of my last knowledge update in October 2023, the iPhone 15 Pro models, including the iPhone 15 Pro and iPhone 15 Pro Max, use a nano-SIM card and support eSIM functionality. This means that in addition to using a physical SIM card, users can also activate cellular plans digitally through eSIM.\\n\\nFor the most accurate and updated specifications, it is recommended to check Apple's official website or technical specifications directly related to the iPhone 15 Pro series.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=MODEL_GPT, messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818a8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help, but I couldn't find any information on an \"iPhone Pro 17\" model. Apple has released several iPhone models over the years, including:\n",
      "\n",
      "* iPhone 4 (2010)\n",
      "* iPhone 5 (2012)\n",
      "* iPhone 5S/5C (2013)\n",
      "* iPhone 6/6 Plus (2014)\n",
      "* iPhone 6S/6S Plus (2015)\n",
      "* iPhone SE (2016)\n",
      "* iPhone 7/7 Plus (2016)\n",
      "* iPhone 8/8 Plus (2017)\n",
      "* iPhone X (2017)\n",
      "* iPhone XS/XS Max/XR (2018)\n",
      "* iPhone 11/11 Pro/11 Pro Max (2019)\n",
      "* iPhone 12/12 mini/12 Pro/12 Pro Max (2020)\n",
      "* iPhone 13/13 mini/13 Pro/13 Pro Max (2021)\n",
      "\n",
      "There is no information available on an \"iPhone Pro 17\" model, as it does not seem to exist.\n",
      "\n",
      "However, I can provide some general information on the typical SIM card specifications for newer Apple iPhones:\n",
      "\n",
      "* SIM card type: Nano-SIM\n",
      "* Frequency bands: GPRS, EDGE, UMTS, HSPA, LTE (4G), 5G\n",
      "* Bands supported: varies by model and region\n",
      "\n",
      "If you could provide more context or clarify which specific model of iPhone you are looking for, I'd be happy to try and provide more detailed information on its SIM card specification.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"not-needed\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "##requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3386f8",
   "metadata": {},
   "source": [
    "Now making a switch between the two local and cloud LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai import OpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG: SWITCH BETWEEN MODELS\n",
    "# -----------------------------\n",
    "\n",
    "USE_LOCAL = False   # ‚Üê change to True to use your local Llama 3.2\n",
    "# USE_LOCAL = True  # ‚Üê for local mode\n",
    "\n",
    "# OpenAI cloud model\n",
    "MODEL_CLOUD = \"gpt-4o-mini\"     # or \"gpt-4.1\", \"gpt-4o\", etc.\n",
    "\n",
    "# Ollama local model (must match 'ollama list')\n",
    "MODEL_LOCAL = \"llama3.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ebef7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü£ Using OPENAI CLOUD model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# INITIALIZE CLIENT\n",
    "# -----------------------------\n",
    "\n",
    "if USE_LOCAL:\n",
    "    print(\"üîµ Using LOCAL Ollama model:\", MODEL_LOCAL)\n",
    "    client = OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        api_key=\"not-needed\"\n",
    "    )\n",
    "    MODEL = MODEL_LOCAL\n",
    "else:\n",
    "    print(\"üü£ Using OPENAI CLOUD model:\", MODEL_CLOUD)\n",
    "    client = OpenAI()        # uses your OPENAI_API_KEY env variable\n",
    "    MODEL = MODEL_CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9fc2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# STREAMING CHAT COMPLETION\n",
    "# -----------------------------\n",
    "\n",
    "def chat_stream(prompt: str):\n",
    "    \"\"\"\n",
    "    Stream model output with live Markdown rendering in Jupyter.\n",
    "    Works for both OpenAI cloud models and local Ollama models.\n",
    "    \"\"\"\n",
    "\n",
    "    # Header\n",
    "    header = f\"### üü¢ Streaming response from `{MODEL}`\\n\\n\"\n",
    "    display_handle = display(Markdown(header), display_id=True)\n",
    "\n",
    "    # Start streaming\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Accumulate markdown output\n",
    "    response = header\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            response += delta.content\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "    # Final footer\n",
    "    response += \"\\n\\n---\\n**‚úì End of stream**\"\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0e04a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üü¢ Streaming response from `gpt-4o-mini`\n",
       "\n",
       "Sure! Let‚Äôs break down these terms into simple definitions:\n",
       "\n",
       "1. **AI (Artificial Intelligence)**: This is a broad field that focuses on creating machines or software that can perform tasks that typically require human intelligence. These tasks might include understanding natural language, recognizing images or patterns, making decisions, and solving problems.\n",
       "\n",
       "2. **ML (Machine Learning)**: This is a subset of AI. It refers to the method by which AI systems learn from data. Instead of being explicitly programmed to perform a task, machine learning algorithms are trained with data to recognize patterns and make predictions or decisions based on new data.\n",
       "\n",
       "3. **Deep Learning**: This is a further subset of machine learning that uses neural networks with multiple layers (hence \"deep\"). It‚Äôs especially powerful for tasks involving unstructured data, like images, audio, and text. Deep learning has enabled significant advancements in areas such as image recognition and natural language processing (NLP).\n",
       "\n",
       "4. **LLM (Large Language Model)**: This refers specifically to deep learning models that are trained on vast amounts of text data to understand and generate human language. LLMs are used in applications like chatbots, language translation, and text summarization. They are part of the deep learning category but focus specifically on language tasks.\n",
       "\n",
       "### Recommended Path to Become an AI Engineer\n",
       "\n",
       "If you're looking to start a career as an AI engineer, here's a suggested path:\n",
       "\n",
       "1. **Start with Basics of AI**: Familiarize yourself with the overall concepts of AI, including its goals and potential applications.\n",
       "\n",
       "2. **Learn Machine Learning**: Dive into machine learning. Understand basic algorithms, concepts of supervised and unsupervised learning, and explore practical implementations using libraries like Scikit-learn.\n",
       "\n",
       "3. **Explore Deep Learning**: Once you have a solid grounding in ML, move on to deep learning. Learn about neural networks, convolutions, and frameworks such as TensorFlow or PyTorch.\n",
       "\n",
       "4. **Focus on LLMs**: If you're particularly interested in natural language processing and conversational AI, then learning about large language models is beneficial. You might explore pre-trained models (like GPT) and how to fine-tune them for specific tasks.\n",
       "\n",
       "In summary, starting with machine learning and gradually progressing to deep learning and then focusing on large language models is a strong pathway to becoming an AI engineer.\n",
       "\n",
       "---\n",
       "**‚úì End of stream**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# RUN TEST\n",
    "# -----------------------------\n",
    "\n",
    "chat_stream(\"Explain the difference between AI, LLM, ML and Deep Learning engineering in simple terms. Which one do you recommend to start with to become an AI Engineer?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv llm_engineering)",
   "language": "python",
   "name": "llm_engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
